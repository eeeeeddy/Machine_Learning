# Regression

**23.05.24 ~23.05.25**

주어진 Feature(X, 독립 변수)와 결정 값(Y, 종속 변수) 데이터 기반에서 학습을 통해 
최적의 회귀 계수(W)를 찾아내는 것이 핵심

최적의 회귀식 모델은 전체 데이터의 잔차(실제 값과 예측 값의 차이)의 합이 최소가 되는 모델을 
만드는 것

- **회귀 유형 구분**
    
    
    | 독립 변수 개수 | 회귀 계수의 결합 |
    | --- | --- |
    | 1개 : 단일 회귀 | 선형 : 선형 회귀 |
    | N개 : 다중 회귀 | 비선형 : 비선형 회귀 |
- **대표적인 선형 회귀 모델**
    - **일반 선형 회귀**
        
        예측값과 실제 값의 RSS(Residual Sum of Squares)를 최소화할 수 있도록 회귀 계수를 
        최적화화며, 규제를 적용하지 않은 모델
        
    - **Ridge**
        
        선형 회귀에 L2 규제를 추가한 회귀 모델
        L2 규제는 상대적으로 큰 회귀 계수 값의 예측 영향도를 감소시키기 위해서 
        회귀 계수 값을 더 작게 만드는 규제 모델
        
    - **Lasso**
        
        선형 회귀에 L1 규제를 적용한 방식
        L2 규제가 회귀 계수 값의 크기를 줄이는 데 반해, L1 규제를 예측 영향력이 작은 피처의
        회귀 계수를 0으로 만들어 회귀 예측 시 피처가 선택되지 않게 하는 것
        이러한 특성 때문에 L1 규제는 피처 선택 기능으로도 불림
        
    - **ElasticNet**
        
        L2, L1 규제를 함께 결합한 모델
        주로 피처가 많은 데이터 세트에서 적용되며, L1 규제로 피처의 개수를 줄임과 동시에
        L2 규제로 계수 값의 크기를 조정
        
    - **Logistic Regression**
        
        회귀라는 말이 붙어있지만 사실은 분류에 사용되는 선형 모델
        매우 강력한 분류 알고리즘이며, 일반적으로 이진 분류뿐만 아니라 
        희소 영역의 분류(예를 들어 텍스트 분류)에서 뛰어난 예측 성능을 보인다.