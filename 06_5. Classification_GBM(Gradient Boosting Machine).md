### GBM(Gradient Boosting Machine)

- **Gradient Boosting Machine**
    - 오류 데이터에 가중치를 부여하면서 부스팅을 수행하는 AdaBoost 알고리즘과 유사하나,
    가중치 업데이트를 **경사 하강법**을 이용
    - 과적합에도 강한 뛰어난 예측 성능을 가진 알고리즘이나 수행시간이 오래 걸린다는 단점이 있다. <br><br>
    
    **사용자 행동 인식 데이터 세트를 이용한 GBM 실습**
    
    ```python
    from sklearn.ensemble import GradientBoostingClassifier
    import time
    import warnings
    warnings.filterwarnings('ignore')
    
    X_train, X_test, y_train, y_test = get_human_dataset()
    
    # GBM 수행 시간 측정을 위함. 시작 시간 설정.
    start_time = time.time()
    
    gb_clf = GradientBoostingClassifier(random_state=0)
    gb_clf.fit(X_train , y_train)
    gb_pred = gb_clf.predict(X_test)
    gb_accuracy = accuracy_score(y_test, gb_pred)
    
    print('GBM 정확도: {0:.4f}'.format(gb_accuracy))
    print("GBM 수행 시간: {0:.1f} 초 ".format(time.time() - start_time))
    ```
    
    ```python
    GBM 정확도: 0.9389
    GBM 수행 시간: 1245.7 초
    ```
    
- **하이퍼 파라미터**
    - loss [Default = ‘deviance’]
        
        경사 하강법에서 사용할 비용 함수 지정
        
    - larning_rate [Default = 0.1 / 범위 : 0~1]
        
        GBM이 학습을 진행할 때마다 적용하는 학습률로 Weak learner가 순차적으로 오류 값을
        보정해 나가는데 적용하는 계수
        
    - n_estimators [Default = 100]
        
        Weak learner의 개수로 Weak learner가 순차적으로 오류를 보정하므로 개수가 많을수록
        예측 성능이 일정 수준까지는 좋아질 수 있다.
        
    - subsample [Default = 1]
        
        Weak learner가 학습에 사용하는 데이터의 샘플링 비율을 의미하며 기본값은 1로 전체 학습 데이터를 기반으로 학습한다는 의미이다. 
        (0.5이면 학습 데이터의 50%)
        
    - max_depth, max_features 등